---
layout: post
title:      "How easy is it to make large mistakes?"
date:       2020-06-21 22:54:37 +0000
permalink:  how_easy_is_it_to_make_large_mistakes
---


It is easy to make large mistakes when trying to do data analysis. Obviously this is the answer that people would tell you because it is a lot of work and everything has to be perfect in order for it to work, but that is something that you are aware of. If you were not aware that you were making a mistake then you would just make the mistake and not think twice. This became obvious to me recently when I was trying to look at some corona virus data. If I was to rank the quality of the health care of each state relative to how it is handling by using the percentage of the population that got corona virus then I would be making a large mistake. I wouldn't neccesarily always have the information that it is largely based on population density not just percentage of people overall who get the disease. I happen to know that piece of information, but I don't always have that insight on all the data sources that I get. I usually like to use metrics that are percentages because without knowing underlying information percentages seem like a smart metric to use. This is why it is important to make sure that analysis is also combined with expert knowledge when using data to make important decisions because without the expert knowledge some of the most commonly straightforward metrics would be completely wrong. 
