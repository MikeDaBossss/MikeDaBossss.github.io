---
layout: post
title:      "Exploring Raw Data"
date:       2019-09-16 17:01:06 +0000
permalink:  exploring_raw_data
---


Raw data is hard to get anything meaningful out of unless there is a lot of processing and manipulation. I'm writing about how to explore raw data because it is something that I have not been able to do with a lot of ease. This blog post will make me learn how to think better about exploring raw data and hopefully if anyone reads this someone will learn some tips. The first step in the process of exploring raw data and getting something useful out of something not useful is to make a visual representation of the data. Making visuals always helps me understand quicker about what the data is and how I can use it. Usually I use matplotlib in python so do my visuals. I like scatter plots because they are easy to understand and to find specific patterns such as categories or trend lines. Once I have a scatter plot I can find outliers, trend lines checking for normality, 
Steps
1. Make the best visual representation
2. look for patterns
3. explore those patterns closer
4. compare patterns to the business needs
5. look for important questions that line up with the patterns
6. come up with hypothesis questions for the null and the alternative

Tips to make the best visual representation would be to explore using seaborn or other plotting libraries that might have more functionality built-in. One function in seaborn that is better than matplotlib is the distplot. This distplot automatically puts a line around the histogram called a kernel density. Histograms are my second favorite plot to use when trying to find information because it works well with categorical data and I can easily see all the information in one plot. Once you have made some graphs to show what the raw data looks like then you must look for patterns in the data. That is why you must first graph the data so then you can find patterns easily. Common patterns that I look for include where linear relationships are, is the data a normal distribution, how many data points do I have, and what else is there besides each seperate column. Do the columns go in a certain order? Now I would have figured out a lot about the raw data and I would start exploring deeper into the patterns that you can intially see. I would make sure to calculate the mean,median,mode, and all the quartiles on the data. I would then compare these things to other pieces of data to try to make more questions on the data. The questions could be just finding more about the data within a certain column, or there could be nothing else besides making models or doing hypothesis testing. After all of these looks into the data I would make sure that I understand the way that the data reflects the business. Why does the business keep all of this data and which pieces of information are the most important pieces of information relative to what the business needs. Usually I figure that businesses are in business to make money so anything related to making more money would be the most important pieces of information. When dealing with SQL databases or other pieces of information where the data is not easy to compare one section of data to another this is where I would start to compare important trends in the data relative to the business needs with different questions that might be worth looking into. Before putting the multiple pieces of data together to try to find important business patterns it is important to make a hypothesis. There must be a null hypothesis and an alternative hypothesis. I usually try to do easier hypothesis testing first and then try the harder problems later once I have gotten a good idea of how to think properly for making hypotheses. One example of a hypothesis would be the null being math is hard, and the alternative being math is not hard. The null is the statement that is the default and since most people don't like math I put the default as math is hard, but if I find out that most people are good at math then the alternative would be true. 
